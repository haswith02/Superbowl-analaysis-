# -*- coding: utf-8 -*-
"""Untitled8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_eCIRmY6sCmxzu6Rmpar64wQBnveVykT

Pre-processing
"""



import pandas as pd
from sklearn.impute import SimpleImputer

super_bowls = pd.read_csv('/super_bowls.csv')
tv_data = pd.read_csv('/tv_data.csv')
halftime_show_artists = pd.read_csv('/halftime_show_artists.csv')

# [1] Missing values before
tv_data.isnull().sum()

# [2] Fill missing numerical and categorical values
tv_data_filled = tv_data.copy()

# Fill numerical columns with mean
num_cols = ['total_us_viewers', 'share_household', 'rating_18_49', 'share_18_49']
tv_data_filled[num_cols] = SimpleImputer(strategy='mean').fit_transform(tv_data_filled[num_cols])

# Fill 'network' column with empty string
tv_data_filled['network'] = tv_data_filled['network'].fillna('')

# [3] Missing values after
tv_data_filled.isnull().sum()

# [5]
super_bowls_filled = super_bowls.fillna('')

# [6]
super_bowls_filled.isnull().sum()

# [7]
halftime_show_artists.isnull().sum()

# [8]
halftime_filled = halftime_show_artists.copy()
halftime_filled['num_songs'] = halftime_filled['num_songs'].fillna(0)
halftime_filled['musician'] = halftime_filled['musician'].fillna('')

# [9]
halftime_filled.isnull().sum()

merged = pd.merge(super_bowls_filled, tv_data_filled, on='super_bowl', how='left')
merged = pd.merge(merged, halftime_filled, on='super_bowl', how='left')
merged.head()

import pandas as pd
from sklearn.impute import SimpleImputer

# Load the dataset (adjust the path as needed)
halftime_show_artists = pd.read_csv('/halftime_show_artists.csv')

# Make a copy of the original dataset
halftime_filled = halftime_show_artists.copy()

# Separate numeric and categorical columns
numeric_cols = halftime_filled.select_dtypes(include=['number']).columns
categorical_cols = halftime_filled.select_dtypes(include=['object']).columns

# Fill numeric columns with the mean
halftime_filled[numeric_cols] = SimpleImputer(strategy='mean').fit_transform(halftime_filled[numeric_cols])

# Fill categorical columns with empty string
for col in categorical_cols:
    halftime_filled[col] = halftime_filled[col].fillna('')

# Check for missing values
print("Missing values after preprocessing:")
print(halftime_filled.isnull().sum())

"""PROJECT"""

import pandas as pd

# Load the CSV data into DataFrames
super_bowls = pd.read_csv('/super_bowls.csv')
tv = pd.read_csv('/tv_data.csv')
halftime_musicians = pd.read_csv('/halftime_show_artists.csv')

# Display the first five rows of each DataFrame
display(super_bowls.head())
display(tv.head())
display(halftime_musicians.head())

tv.info()

print('\n')

# Summary of the halftime musician data to inspect
halftime_musicians.info()

# Commented out IPython magic to ensure Python compatibility.

!pip install seaborn

from matplotlib import pyplot as plt
import seaborn as sns
import pandas as pd

# %matplotlib inline

sns.set_theme()

plt.figure(figsize=(10, 6))
plt.hist(super_bowls['combined_pts'], bins=10, edgecolor='black')
plt.xlabel('Combined Points')
plt.ylabel('Number of Super Bowls')
plt.title('Distribution of Combined Points in Super Bowls')
plt.grid(True)
plt.show()

print("Super Bowls with combined points > 70:")
display(super_bowls[super_bowls['combined_pts'] > 70])

print("Super Bowls with combined points < 30:")
display(super_bowls[super_bowls['combined_pts'] < 30])

plt.hist(super_bowls.difference_pts)
plt.xlabel('Point Difference')
plt.ylabel('Number of Super Bowls')
plt.show()

# Display the closest game(s) and biggest blowouts
display(super_bowls[super_bowls['difference_pts'] == 1])
display(super_bowls[super_bowls['difference_pts'] >= 35])

games_tv = pd.merge(tv[tv['super_bowl'] > 1], super_bowls, on='super_bowl')

# Import seaborn
import seaborn as sns

games_tv.head()

# Create a scatter plot with a linear regression model fit
sns.regplot(x=games_tv['difference_pts'], y=games_tv['share_household'])

plt.subplot(3, 1, 1)
plt.plot(tv.super_bowl, tv.avg_us_viewers, color='#648FFF')
plt.title('Average Number of US Viewers')

plt.subplot(3, 1, 2)
plt.plot(tv.super_bowl, tv.rating_household, color='#DC267F')
plt.title('Household Rating')

plt.subplot(3, 1, 3)
plt.plot(tv.super_bowl, tv.ad_cost, color='#FFB000')
plt.title('Ad Cost')
plt.xlabel('SUPER BOWL')

plt.tight_layout()

halftime_musicians[halftime_musicians.super_bowl <= 27]

halftime_appearances = halftime_musicians.groupby('musician').count()['super_bowl'].reset_index()
halftime_appearances = halftime_appearances.sort_values('super_bowl', ascending=False)

# Display musicians with more than one halftime show appearance
halftime_appearances.head()

halftime_appearances[halftime_appearances.super_bowl > 1]

no_bands = halftime_musicians[~halftime_musicians.musician.str.contains('Marching')]
no_bands = no_bands[~no_bands.musician.str.contains('Spirit')]

# Plot a histogram of number of songs per performance
most_songs = int(max(no_bands['num_songs'].values))
plt.hist(no_bands.num_songs.dropna(), bins=most_songs)
plt.xlabel('Number of Songs Per Halftime Show Performance')
plt.ylabel('Number of Musicians')
plt.show()

# Sort the non-band musicians by number of songs per appearance...
no_bands = no_bands.sort_values('num_songs', ascending=False)
display(no_bands.head(15))

patriots = 'New England Patriots'
rams = 'Los Angeles Rams'

# Who will win Super Bowl LIII?
super_bowl_LIII_winner = rams
print('The winner of Super Bowl LIII will be the', super_bowl_LIII_winner)

correlation = games_tv[['difference_pts', 'share_household']].corr()
print(correlation)

from scipy.stats import ttest_ind

# Define two eras (example: before and after 2000)
era_1 = tv[tv['super_bowl'] < 2000]['avg_us_viewers']
era_2 = tv[tv['super_bowl'] >= 2000]['avg_us_viewers']

# Perform T-test
t_stat, p_value = ttest_ind(era_1, era_2)

print("T-test results:")
print(f"T-statistic: {t_stat}, P-value: {p_value}")

if p_value < 0.05:
    print("Statistically significant difference in viewership between eras.")
else:
    print("No significant difference in viewership between eras.")

from scipy.stats import f_oneway

# Divide into decades
era_70s = tv[(tv['super_bowl'] >= 1970) & (tv['super_bowl'] < 1980)]['avg_us_viewers']
era_80s = tv[(tv['super_bowl'] >= 1980) & (tv['super_bowl'] < 1990)]['avg_us_viewers']
era_90s = tv[(tv['super_bowl'] >= 1990) & (tv['super_bowl'] < 2000)]['avg_us_viewers']
era_2000s = tv[(tv['super_bowl'] >= 2000) & (tv['super_bowl'] < 2010)]['avg_us_viewers']
era_2010s = tv[(tv['super_bowl'] >= 2010)]['avg_us_viewers']

# Perform ANOVA test
f_stat, p_value = f_oneway(era_70s, era_80s, era_90s, era_2000s, era_2010s)

print("ANOVA results:")
print(f"F-statistic: {f_stat}, P-value: {p_value}")

if p_value < 0.05:
    print("Statistically significant differences in viewership across decades.")
else:
    print("No significant difference in viewership across decades.")

import matplotlib.pyplot as plt

# Compute 5-year moving averages
tv['viewers_ma'] = tv['avg_us_viewers'].rolling(window=5).mean()
tv['ad_cost_ma'] = tv['ad_cost'].rolling(window=5).mean()

# Plot moving averages
plt.figure(figsize=(10, 5))

plt.subplot(2, 1, 1)
plt.plot(tv['super_bowl'], tv['viewers_ma'], label="Viewership", color='blue')
plt.xlabel("Super Bowl")
plt.ylabel("Viewers (millions)")
plt.title("5-Year Moving Average of Super Bowl Viewership")
plt.legend()

plt.subplot(2, 1, 2)
plt.plot(tv['super_bowl'], tv['ad_cost_ma'], label="Ad Cost", color='red')
plt.xlabel("Super Bowl")
plt.ylabel("Ad Cost (millions)")
plt.title("5-Year Moving Average of Super Bowl Ad Costs")
plt.legend()

plt.tight_layout()
plt.show()

from sklearn.linear_model import LinearRegression

X = tv[['super_bowl']]  # Years as independent variable
y = tv['ad_cost']  # Ad costs as target variable

model = LinearRegression().fit(X, y)
future_years = [[2026], [2027], [2028]]  # Future Super Bowls
predicted_costs = model.predict(future_years)
print(predicted_costs)

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

# Define high-scoring games (Threshold = 48 points)
super_bowls['high_scoring'] = (super_bowls['combined_pts'] > 48).astype(int)

# Select features
X = super_bowls[['super_bowl', 'difference_pts']]  # You can add more features
y = super_bowls['high_scoring']  # Target variable (1 = High scoring, 0 = Low scoring)

# Split data (80% training, 20% testing)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Train Logistic Regression model
model = LogisticRegression()
model.fit(X_train, y_train)

# Predictions
y_pred = model.predict(X_test)

# Evaluate model
accuracy = accuracy_score(y_test, y_pred)
print(f"Model Accuracy: {accuracy:.2f}")
print(classification_report(y_test, y_pred))

tv[['super_bowl', 'ad_cost']].head()

tv[['super_bowl', 'ad_cost']].describe()

import pandas as pd
import matplotlib.pyplot as plt
from prophet import Prophet

# Convert Super Bowl numbers to actual years
tv['year'] = tv['super_bowl'] + 1966

# Prepare data for Prophet
df = tv[['year', 'ad_cost']].rename(columns={'year': 'ds', 'ad_cost': 'y'})

# Convert 'ds' column to datetime format
df['ds'] = pd.to_datetime(df['ds'], format='%Y')

# Initialize and fit the Prophet model
model = Prophet()
model.fit(df)

# Create future dates for prediction
future = model.make_future_dataframe(periods=10, freq='Y')  # Predict 10 years ahead
forecast = model.predict(future)

# Show future predictions
future_ad_costs = forecast[['ds', 'yhat']].rename(columns={'ds': 'year', 'yhat': 'predicted_ad_cost'})
print(future_ad_costs.tail(10))  # Show the last few predictions

# Plot the forecast
model.plot(forecast)
plt.title("Super Bowl Ad Cost Prediction (Prophet)")
plt.xlabel("Year")
plt.ylabel("Ad Cost (Millions)")
plt.show()